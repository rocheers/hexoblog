<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge" />
    
    <title>Selenium和BeautifulSoup的简单应用：爬取Pythonbooks.org | X space</title>
    <meta name="description" content="Information -&gt; Knowledge -&gt; Wisdom" />
    <meta name="keywords" content="" />
    <meta name="HandheldFriendly" content="True" />
    <meta name="apple-mobile-web-app-capable" content="yes">
    <link rel="shortcut icon" href="/images/favicon.png">
    <link rel="alternate" href="/atom.xml" title="X space">
    <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">
    <meta name="description" content="使用Python是个很有意思的体验，语法相对简单，各种包的支持也非常到位，因此无论用Python解决什么问题，都觉得弹指间可以让其灰飞烟灭。作为一个工具，一种编程语言，在帮助不同人群实现各种有趣的小目标这点上，Python真的是无出其右。 本文目的Python中有一种很好玩的应用，就是爬虫，简单说就是通过它，用户可以抓取网页上的信息。比如，在本篇文章中，我就将介绍自己爬取Pythonbooks网站">
<meta name="keywords" content="Python,Selenium,BeautifulSoup,crawler">
<meta property="og:type" content="article">
<meta property="og:title" content="Selenium和BeautifulSoup的简单应用：爬取Pythonbooks.org">
<meta property="og:url" content="http://yuannow.com/2017/11/06/Python-Books-Crawler/index.html">
<meta property="og:site_name" content="X space">
<meta property="og:description" content="使用Python是个很有意思的体验，语法相对简单，各种包的支持也非常到位，因此无论用Python解决什么问题，都觉得弹指间可以让其灰飞烟灭。作为一个工具，一种编程语言，在帮助不同人群实现各种有趣的小目标这点上，Python真的是无出其右。 本文目的Python中有一种很好玩的应用，就是爬虫，简单说就是通过它，用户可以抓取网页上的信息。比如，在本篇文章中，我就将介绍自己爬取Pythonbooks网站">
<meta property="og:locale" content="zh-CN">
<meta property="og:image" content="http://yuannow.com/images/crawl/website.png">
<meta property="og:image" content="http://yuannow.com/images/crawl/menu.png">
<meta property="og:image" content="http://yuannow.com/images/crawl/crawl_menu.png">
<meta property="og:image" content="http://yuannow.com/images/crawl/crawl_book.png">
<meta property="og:image" content="http://yuannow.com/images/crawl/md_files.png">
<meta property="og:image" content="http://yuannow.com/images/crawl/md_file.png">
<meta property="og:image" content="http://yuannow.com/images/crawl/md_result.png">
<meta property="og:updated_time" content="2017-11-07T02:47:10.000Z">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="Selenium和BeautifulSoup的简单应用：爬取Pythonbooks.org">
<meta name="twitter:description" content="使用Python是个很有意思的体验，语法相对简单，各种包的支持也非常到位，因此无论用Python解决什么问题，都觉得弹指间可以让其灰飞烟灭。作为一个工具，一种编程语言，在帮助不同人群实现各种有趣的小目标这点上，Python真的是无出其右。 本文目的Python中有一种很好玩的应用，就是爬虫，简单说就是通过它，用户可以抓取网页上的信息。比如，在本篇文章中，我就将介绍自己爬取Pythonbooks网站">
<meta name="twitter:image" content="http://yuannow.com/images/crawl/website.png">
    
    <link href="https://fonts.googleapis.com/css?family=Inconsolata|Titillium+Web" rel="stylesheet">
    <link href="https://fonts.googleapis.com/css?family=Roboto+Mono" rel="stylesheet">
    <link href='//cdn.bootcss.com/node-waves/0.7.5/waves.min.css' rel='stylesheet'>
    <link rel="stylesheet" href="/style.css">
    <script>
      function setLoadingBarProgress(num) {
        document.getElementById('loading-bar').style.width=num+"%";
      }
    </script>
    
      <!-- Global Site Tag (gtag.js) - Google Analytics -->
      <script async src="https://www.googletagmanager.com/gtag/js?id=UA-107727758-1"></script>
      <script>
        window.dataLayer = window.dataLayer || [];
        function gtag(){dataLayer.push(arguments);}
        gtag('js', new Date());
        gtag('config', 'UA-107727758-1');
      </script>
    
  </head>
<body>
  <div id="loading-bar-wrapper">
  <div id="loading-bar"></div>
</div>


  <script>setLoadingBarProgress(20)</script> 
  <header class="l_header">
	<div class='wrapper'>
		<div class="nav-main container container--flex">
			<a class="logo flat-box" href='/' >
				X space
			</a>
			<div class='menu'>
				<ul class='h-list'>
					
						<li>
							<a class='flat-box nav-home' href='/'>
								Home
							</a>
						</li>
					
						<li>
							<a class='flat-box nav-archives' href='/archives'>
								Archives
							</a>
						</li>
					
						<li>
							<a class='flat-box nav-gallery' href='/gallary'>
								Gallery
							</a>
						</li>
					
						<li>
							<a class='flat-box nav-about' href='/about'>
								About
							</a>
						</li>
					
				</ul>
				<div class='underline'></div>
			</div>
			
				<div class="m_search">
					<form name="searchform" class="form u-search-form">
						<input type="text" class="input u-search-input" placeholder="Search" />
						<span class="icon icon-search"></span>
					</form>
				</div>
			
			<ul class='switcher h-list'>
				
					<li class='s-search'><a href='javascript:void(0)'><span class="icon icon-search flat-box"></span></a></li>
				
				<li class='s-menu'><a href='javascript:void(0)'><span class="icon icon-menu flat-box"></span></a></li>
			</ul>
		</div>
		
		<div class='nav-sub container container--flex'>
			<a class="logo" class="flat-box" href='javascript:void(0)'>
				Word of Forks
			</a>

			<ul class='switcher h-list'>
				<li class='s-comment'><a href='javascript:void(0)'><span class="icon icon-chat_bubble_outline flat-box"></span></a></li>
				<li class='s-top'><a href='javascript:void(0)'><span class="icon icon-arrow_upward flat-box"></span></a></li>
				<li class='s-toc'><a href='javascript:void(0)'><span class="icon icon-format_list_numbered flat-box"></span></a></li>
			</ul>
		</div>
	</div>
</header>
<aside class="menu-phone">
	<nav>
		
			<a href="/" class="nav-home nav">
				Home
			</a>
		
			<a href="/archives" class="nav-archives nav">
				Archives
			</a>
		
			<a href="/gallary" class="nav-gallery nav">
				Gallery
			</a>
		
			<a href="/about" class="nav-about nav">
				About
			</a>
		
	</nav>
</aside>

    <script>setLoadingBarProgress(40);</script>
  <div class="l_body">
    <div class='container clearfix'>
      <div class='l_main'>
        <article id="post-Python-Books-Crawler" class="post white-box article-type-post" itemscope itemprop="blogPost">
    <section class='meta'>
        <h2 class="title">
            <a href="/2017/11/06/Python-Books-Crawler/">
                Selenium和BeautifulSoup的简单应用：爬取Pythonbooks.org
            </a>
        </h2>
        <time>
	  11月 6, 2017
	</time>
        
    
    <div class='cats'>
        <a href="/categories/Web-Application/">Web Application</a>
    </div>

    </section>
    
        <section class="toc-wrapper">
            <ol class="toc"><li class="toc-item toc-level-1"><a class="toc-link" href="#本文目的"><span class="toc-number">1.</span> <span class="toc-text">本文目的</span></a></li><li class="toc-item toc-level-1"><a class="toc-link" href="#环境需求"><span class="toc-number">2.</span> <span class="toc-text">环境需求</span></a></li><li class="toc-item toc-level-1"><a class="toc-link" href="#Selenium和BeautifulSoup"><span class="toc-number">3.</span> <span class="toc-text">Selenium和BeautifulSoup</span></a></li><li class="toc-item toc-level-1"><a class="toc-link" href="#网站爬取"><span class="toc-number">4.</span> <span class="toc-text">网站爬取</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#初始化webdriver"><span class="toc-number">4.1.</span> <span class="toc-text">初始化webdriver</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#爬取分类"><span class="toc-number">4.2.</span> <span class="toc-text">爬取分类</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#爬取书籍信息"><span class="toc-number">4.3.</span> <span class="toc-text">爬取书籍信息</span></a></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#存储书籍信息"><span class="toc-number">5.</span> <span class="toc-text">存储书籍信息</span></a></li><li class="toc-item toc-level-1"><a class="toc-link" href="#主函数：功能串联"><span class="toc-number">6.</span> <span class="toc-text">主函数：功能串联</span></a></li><li class="toc-item toc-level-1"><a class="toc-link" href="#结语"><span class="toc-number">7.</span> <span class="toc-text">结语</span></a></li><li class="toc-item toc-level-1"><a class="toc-link" href="#Related-Links"><span class="toc-number">8.</span> <span class="toc-text">Related Links</span></a></li></ol>
        </section>
        
            <section class="article typo">
                <div class="article-entry" itemprop="articleBody">
                    <p>使用Python是个很有意思的体验，语法相对简单，各种包的支持也非常到位，因此无论用Python解决什么问题，都觉得弹指间可以让其灰飞烟灭。作为一个工具，一种编程语言，在帮助不同人群实现各种有趣的小目标这点上，Python真的是无出其右。</p>
<h1 id="本文目的"><a href="#本文目的" class="headerlink" title="本文目的"></a>本文目的</h1><p>Python中有一种很好玩的应用，就是爬虫，简单说就是通过它，用户可以抓取网页上的信息。比如，在本篇文章中，我就将介绍自己爬取Pythonbooks网站的过程，以此来让各位对爬虫有个大概的认识，并且描述过程中我也会顺带介绍一下Selenium和BeautifulSoup两个爬虫中常用包的用法。</p>
<a id="more"></a>
<p>在Python的学习过程中，我相信每一位“Pythoner”都会经历这样一个过程：市面上这么多本Python的书籍和教程，究竟哪一个才是最好的呢？国外有个叫<em>Dibya Chakravorty</em>的哥们在当初学习Python的时候也思考到这个问题，于是他就做了一个网站，<code>Pythonbooks.org</code>，专门来统计不同应用领域下的Python书籍，以及它们的评分，评分是根据书的销售情况来计算的。所以今天我就用爬虫的方式来带各位看一下他网站上是怎么说的。</p>
<hr>
<h1 id="环境需求"><a href="#环境需求" class="headerlink" title="环境需求"></a>环境需求</h1><p>我是在Python3下运行的爬虫，用到的包就两个：<code>Selenium</code>和<code>BeautifulSoup</code>，安装最新版就可以。</p>
<p>下面我们先来看一下这两个包究竟都是做什么的，为什么我会用到它们。</p>
<hr>
<h1 id="Selenium和BeautifulSoup"><a href="#Selenium和BeautifulSoup" class="headerlink" title="Selenium和BeautifulSoup"></a>Selenium和BeautifulSoup</h1><p>打开Selenium官网，第一句话就是 <em>Selenium automates browsers.</em> 。没了，就这一句，就说明了Selenium的作用，它就是用来模拟操作浏览器的工具，通过API，用户可以用代码来操作浏览器上网页的跳转，关闭，填写表单等操作。</p>
<p>那BeautifulSoup的作用呢？以下引用Wikipedia：</p>
<blockquote>
<p>Beautiful Soup is a Python package for parsing HTML and XML documents (including having malformed markup, i.e. non-closed tags, so named after tag soup). It creates a parse tree for parsed pages that can be used to extract data from HTML, which is useful for web scraping.</p>
</blockquote>
<p>所以BeautifulSoup的作用就是用来从HTML和XML等文件中提取所需信息。BeautifulSoup实际上是bs4模块的一个子模块，bs4的作用极其强大，可以针对各种内容分割和获取信息，BeautifulSoup是其专门针对HTML和XML的。因为本文只用到BeautifulSoup，因此其他的模块内容就暂不介绍了，有兴趣的朋友可以自行查阅。</p>
<p>简单介绍两个工具包之后，接下来让我们开始网站的爬取工作吧。</p>
<hr>
<h1 id="网站爬取"><a href="#网站爬取" class="headerlink" title="网站爬取"></a>网站爬取</h1><p>在正式爬取之前，我们还有一个问题需要解决，就是这个网站的规模和动态程度，如果只是纯静态网页，而且只要爬取一个页面，那其实很容易。或者如果只要爬取3、5个网页，那我们完全可以手动跳转每个网页然后运行一遍程序，也不过就运行3、5遍而已，但当网页数量比较多的时候，这么不自动化的办法就显得很麻烦。</p>
<p><img src="/images/crawl/website.png" alt="website"></p>
<p><img src="/images/crawl/menu.png" alt="menu"></p>
<p>这个网站上已经针对不同领域，为用户区分好了所有的Python书籍归属种类。这点真的非常方便，这样我就只需要按照他网站给出的分类分别爬取下来就可以了，但这里种类的繁多，一个网页一个网页的手动跳转就很麻烦了，所以这里就需要Selenium来模拟鼠标的点击操作，进行网页的跳转，然后用BS爬取内容。这就是整个爬取过程的初步思考。</p>
<hr>
<h2 id="初始化webdriver"><a href="#初始化webdriver" class="headerlink" title="初始化webdriver"></a>初始化webdriver</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div></pre></td><td class="code"><pre><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">init_driver</span><span class="params">()</span>:</span></div><div class="line">    driver = webdriver.Firefox()</div><div class="line">    <span class="comment"># driver.wait = WebDriverWait(driver, 5)</span></div><div class="line">    <span class="keyword">return</span> driver</div></pre></td></tr></table></figure>
<p>用Selenium来模拟浏览器的各种行为，就需要先进行webdriver的初始化，如上面的代码所示。中间注释掉的那一行可加可不加，它的作用主要就是考虑到有些网页是动态呈现内容，在输入网址之后加载网页到完全加载完毕可能需要等待一段时间，WebDriverWait就是用来告诉driver可以考虑的等待时间范围。一般来说都会搭配该类下的unitil、until_not方法和expected_conditions使用，本文用不到这些内容，所以就不深讲了，有兴趣的朋友可以看<a href="https://huilansame.github.io/huilansame.github.io/archivers/sleep-implicitlywait-wait" target="_blank" rel="external">这里</a></p>
<hr>
<h2 id="爬取分类"><a href="#爬取分类" class="headerlink" title="爬取分类"></a>爬取分类</h2><p>从这里开始，我们就要正式爬取网站内容了。首先需要先把所有的分类获取，这样也方便我们最后整理信息，无论是以哪种方式存储。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div></pre></td><td class="code"><pre><div class="line">url = <span class="string">"http://pythonbooks.org/"</span></div><div class="line">menu = [<span class="string">"Intermediate"</span>, <span class="string">"Topical"</span>, <span class="string">"Others"</span>]</div><div class="line">categories = &#123;<span class="string">'Beginner'</span>: <span class="string">'http://pythonbooks.org/for-programming-beginners'</span>&#125;</div><div class="line">    </div><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">crawl_category</span><span class="params">(driver, url, categories, menu)</span>:</span></div><div class="line">    driver.get(url)</div><div class="line">    <span class="keyword">for</span> m <span class="keyword">in</span> menu:</div><div class="line">        sub_menus = &#123;&#125;</div><div class="line">        driver.find_element_by_link_text(m).click()</div><div class="line">        </div><div class="line">        <span class="comment"># 停顿一下以等待下级菜单的弹出</span></div><div class="line">        time.sleep(<span class="number">0.2</span>)</div><div class="line">        <span class="keyword">try</span>:</div><div class="line">            sub_menu_block = driver.find_element_by_xpath(<span class="string">"//li[@class='dropdown open']"</span>)</div><div class="line">            sub_menu_name = sub_menu_block.find_element_by_tag_name(<span class="string">"ul"</span>)</div><div class="line">            <span class="keyword">for</span> sub_menu, sub_menu_link <span class="keyword">in</span> zip(sub_menu_name.text.split(<span class="string">'\n'</span>), sub_menu_name.find_elements_by_css_selector(<span class="string">'a'</span>)):</div><div class="line">                sub_menus[sub_menu] = sub_menu_link.get_attribute(<span class="string">'href'</span>)</div><div class="line">        <span class="keyword">except</span> NoSuchElementException:</div><div class="line">            <span class="keyword">pass</span></div><div class="line">            </div><div class="line">        categories[m] = sub_menus</div></pre></td></tr></table></figure>
<p>这里有细心的朋友可能看到我一开始给了一个categories的字典变量，里面有内容，而不是空的。这里之所以这样做，是因为在网页上显示的四个总分类中，只有Beginner是没有下级菜单的，所以这里就单独处理一下。</p>
<p>代码中<code>driver.find_element_by_xpath(&quot;//li[@class=&#39;dropdown open&#39;]&quot;)</code>，这句就是获得了弹出的下级菜单中的内容。具体的对照请看下图：</p>
<p><img src="/images/crawl/crawl_menu.png" alt="crawl_menu"></p>
<p><code>for</code>循环中，两个遍历的变量，前者是获取的分类的string值，后者是对应的链接地址。我将它们都存进一个字典中，这样在下面爬取内容的时候，只需要对该字典遍历一遍就可以了。</p>
<hr>
<h2 id="爬取书籍信息"><a href="#爬取书籍信息" class="headerlink" title="爬取书籍信息"></a>爬取书籍信息</h2><p>上面我们已经将书籍分类都汇总好了，下面就开始挨个网页的爬取书籍的信息。这里书籍的信息我主要就爬取了五个：标题，作者，出版日期，分数，和封面图像。为了存储和打印方便，我就讲书籍信息封装成一个类，如下所示：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div></pre></td><td class="code"><pre><div class="line"><span class="class"><span class="keyword">class</span> <span class="title">BookInfo</span><span class="params">()</span>:</span></div><div class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self, title, author, score, pub_date, href)</span>:</span></div><div class="line">        self.title = title</div><div class="line">        self.author = author</div><div class="line">        self.score = score</div><div class="line">        self.pub_date = pub_date</div><div class="line">        self.href = href</div><div class="line">        </div><div class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__str__</span><span class="params">(self)</span>:</span></div><div class="line">        <span class="keyword">return</span> <span class="string">"Book '&#123;&#125;' written by &#123;&#125;, &#123;&#125;. Popularity score: &#123;&#125;"</span>.format(self.title, self.author, self.pub_date, self.score)</div></pre></td></tr></table></figure>
<p>接下来就是对页面的爬取工作，先贴代码：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div></pre></td><td class="code"><pre><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">crawl_book_info</span><span class="params">(driver, url)</span>:</span></div><div class="line">    driver.get(url)</div><div class="line">    html = driver.page_source</div><div class="line">    </div><div class="line">    <span class="comment"># 等待网页加载分数</span></div><div class="line">    time.sleep(<span class="number">2</span>)</div><div class="line">    </div><div class="line">    soup = BeautifulSoup(html, <span class="string">'html.parser'</span>)</div><div class="line">    </div><div class="line">    book_blocks = soup.find(<span class="string">'div'</span>, id=<span class="string">'result-content'</span>)</div><div class="line">    </div><div class="line">    book_block_list = []</div><div class="line">    <span class="keyword">for</span> book_block <span class="keyword">in</span> book_blocks.find_all(class_=<span class="string">'row book-wrapper-row'</span>):</div><div class="line">        book_block_list.append(book_block)</div><div class="line">    </div><div class="line">    book_list = []</div><div class="line">    scores = driver.find_elements_by_xpath(<span class="string">"//div[@class='bar']"</span>)</div><div class="line">    <span class="keyword">for</span> book, score <span class="keyword">in</span> zip(book_block_list, scores):</div><div class="line">        title = book.find(<span class="string">'h2'</span>).string</div><div class="line">        pub_date = book.find(<span class="string">'span'</span>, class_=<span class="string">"publication-date"</span>).string.strip()</div><div class="line">        author = book.find(<span class="string">'h3'</span>).string.strip()[<span class="number">3</span>:]</div><div class="line">        href = book.find(<span class="string">'img'</span>)[<span class="string">'src'</span>]</div><div class="line">        book_list.append(BookInfo(title, author, score.text, pub_date, href))</div><div class="line">        </div><div class="line">    <span class="keyword">return</span> book_list</div></pre></td></tr></table></figure>
<p>内容比较多，我们一点点来看。首先我们看看每个字段的位置。</p>
<p><img src="/images/crawl/crawl_book.png" alt="crawl_book"></p>
<p>我在一开始做这部分的时候是想用BS就可以了，因为在HTML中各元素的位置一目了然，爬取十分方便。但后来发现分数这一项，死活爬不下来，每次用BS去找这一块，返回的都是空。猜测可能是分数是动态生成的关系，因此BS抓取不到，具体内在原因没有去详细了解，如果有大神知道是怎么回事，还希望不吝赐教。后来我实在没有办法，就只好改用Selenium来抓取，<code>driver.find_elements_by_xpath(&quot;//div[@class=&#39;bar&#39;]&quot;)</code>。正因为分数是动态生成，所以在加载网页之后需要给一个延迟，等一下分数的刷新。分数和书籍是一一对应的，所以在<code>for</code>循环中用<code>zip</code>对两者一起进行协同遍历就可以了。</p>
<hr>
<h1 id="存储书籍信息"><a href="#存储书籍信息" class="headerlink" title="存储书籍信息"></a>存储书籍信息</h1><p>我们已经将书籍信息全部抓取下来，下面就是要考虑如何存储的问题。我这里是将所有的书按照分类（如果有第二级分类，就按照第二级）存储到一个markdown文件里。markdown最大的有点是，很方便转成html文件，这样既利于存储也利于展示。代码如下，因为这部分比较简单，我想就不用解释太多了。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div></pre></td><td class="code"><pre><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">book_save</span><span class="params">(books_list, cat, sub_cat=None)</span>:</span></div><div class="line">    </div><div class="line">    <span class="comment"># 如果存在二级分类，就把一级二级拼起来作为文件名</span></div><div class="line">    title = str(cat) + <span class="string">'-'</span> + str(sub_cat) <span class="keyword">if</span> sub_cat <span class="keyword">else</span> str(cat)</div><div class="line">    </div><div class="line">    <span class="keyword">with</span> open(<span class="string">'../Pythonbooks-'</span> + title + <span class="string">'.md'</span>, <span class="string">'w'</span>) <span class="keyword">as</span> file:</div><div class="line">        <span class="keyword">if</span> <span class="keyword">not</span> sub_cat:</div><div class="line">            file.write(<span class="string">"# &#123;&#125;\n\n"</span>.format(cat))</div><div class="line">        <span class="keyword">else</span>:</div><div class="line">            file.write(<span class="string">"# &#123;&#125; - &#123;&#125;\n\n"</span>.format(cat, sub_cat))</div><div class="line">        num = <span class="number">1</span></div><div class="line">        <span class="keyword">for</span> book <span class="keyword">in</span> books_list:</div><div class="line">            file.write(<span class="string">"## &#123;&#125;. &#123;&#125;\n"</span>.format(num, book.title))</div><div class="line">            file.write(<span class="string">"![&#123;&#125;_cover](&#123;&#125;)\n\n"</span>.format(book.title, book.href))</div><div class="line">            file.write(<span class="string">"Author: &#123;&#125;\n\n"</span>.format(book.author))</div><div class="line">            file.write(<span class="string">"&#123;&#125;\n\n"</span>.format(book.pub_date))</div><div class="line">            file.write(<span class="string">"**Popularity score: &#123;&#125;**\n\n"</span>.format(book.score))</div><div class="line">            file.write(<span class="string">"------------\n"</span>)</div><div class="line">            num += <span class="number">1</span></div></pre></td></tr></table></figure>
<hr>
<h1 id="主函数：功能串联"><a href="#主函数：功能串联" class="headerlink" title="主函数：功能串联"></a>主函数：功能串联</h1><p>主函数主要就是将各个部分串联起来，具体代码如下：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">if</span> __name__ == <span class="string">"__main__"</span>:</div><div class="line">    url = <span class="string">"http://pythonbooks.org/"</span></div><div class="line">    menu = [<span class="string">"Intermediate"</span>, <span class="string">"Topical"</span>, <span class="string">"Others"</span>]</div><div class="line">    categories = &#123;<span class="string">'Beginner'</span>: <span class="string">'http://pythonbooks.org/for-programming-beginners'</span>&#125;</div><div class="line">    </div><div class="line">    driver = init_driver()</div><div class="line">    crawl_category(driver, url, categories, menu)</div><div class="line">    </div><div class="line">    all_books = &#123;&#125;</div><div class="line">    </div><div class="line">    <span class="keyword">for</span> key, value <span class="keyword">in</span> categories.items():</div><div class="line">    </div><div class="line">        <span class="comment"># 如果一级分类的value是字典的话，那就说明还存在二级分类</span></div><div class="line">        <span class="keyword">if</span> key <span class="keyword">not</span> <span class="keyword">in</span> all_books <span class="keyword">and</span> <span class="keyword">not</span> isinstance(value, str):</div><div class="line">            all_books[key] = &#123;&#125;</div><div class="line">            </div><div class="line">        <span class="keyword">try</span>:</div><div class="line">            <span class="keyword">for</span> k, v <span class="keyword">in</span> value.items():</div><div class="line">                book_list = crawl_book_info(driver, v)</div><div class="line">                all_books[key][k] = book_list</div><div class="line">                book_save(book_list, key, sub_cat=k)</div><div class="line">        <span class="keyword">except</span>:</div><div class="line">            book_list = crawl_book_info(driver, value)</div><div class="line">            all_books[key] = book_list</div><div class="line">            book_save(book_list, key)</div><div class="line">            </div><div class="line">    driver.quit()</div></pre></td></tr></table></figure>
<p>在所有的分类中，只有<code>Beginner</code>是没有二级分类的，因此需要对它进行单独处理。对应到代码中，就是except下面的内容。</p>
<p>我在主函数里还设置了一个<code>all_books</code>的变量，但其实并没有用到。因为一开始我本打算先存到一个字典变量中在，再对该变量进行遍历，一个一个将书籍信息存到文件中。后来发现其实并不需要，完全可以边爬取边存。</p>
<p>好了，所有的爬取内容就都结束了，当你运行程序之后就会看到Firfox浏览器自动弹出，然后逐个页面的自己跳转，最后浏览器关闭的时候，你也就收获了一大堆的md文件。
<img src="/images/crawl/md_files.png" alt="md_files"></p>
<p>md的内容如下图所示：
<img src="/images/crawl/md_file.png" alt="md_file"></p>
<p>将md渲染成HTML后在网页中显示是这样的：
<img src="/images/crawl/md_result.png" alt="md_result"></p>
<hr>
<h1 id="结语"><a href="#结语" class="headerlink" title="结语"></a>结语</h1><p>相对来说，这次的爬取任务很简单，因为网站没有反爬机制。其实在爬取过程中，最难的，最体现斗智斗勇的地方，就是反爬与反反爬，这方面我不是很了解。因为一般用到爬虫的时候都是确实切身需要的时候，并非为了技术而去钻研，所以大部分时候爬的都是一些明面上的可搜集的数据。网上关于Python爬虫的介绍和例子其实有很多很多，现如今，除了数据分析，机器学习这部分，恐怕大多数人都是因为爬虫的趣味性和实用性在学Python吧。</p>
<p>在本文的最后，我给出了几个很有帮助的链接，对于想要学习Selenium和BeautifulSoup的朋友，值得一看。</p>
<hr>
<h1 id="Related-Links"><a href="#Related-Links" class="headerlink" title="Related Links"></a>Related Links</h1><ol>
<li><a href="https://huilansame.github.io/huilansame.github.io/archivers/sleep-implicitlywait-wait" target="_blank" rel="external">Python Selenium——一定要会用的Selenium的等待，三种等待方式解读</a></li>
<li><a href="https://python-selenium-zh.readthedocs.io/zh_CN/latest/" target="_blank" rel="external">selenium + python 中文文档</a></li>
<li><a href="https://www.crummy.com/software/BeautifulSoup/bs4/doc/index.zh.html" target="_blank" rel="external">Beautiful Soup 4.2.0 中文文档</a></li>
<li><a href="http://wiki.jikexueyuan.com/project/python-crawler-guide/beautiful-soup.html" target="_blank" rel="external">Beautiful Soup 的用法</a></li>
<li><a href="http://cuiqingcai.com/2599.html" target="_blank" rel="external">Python爬虫利器五之Selenium的用法</a></li>
</ol>

                </div>
                
                    <div class="article-tags tags">
                        
                            <a href="/tags/Python/">
                                Python
                            </a>
                            
                            <a href="/tags/Selenium/">
                                Selenium
                            </a>
                            
                            <a href="/tags/BeautifulSoup/">
                                BeautifulSoup
                            </a>
                            
                            <a href="/tags/crawler/">
                                crawler
                            </a>
                            
                    </div>
                    

                        
                            <div class="art-item-footer">
                                
                                        
                                            <span class="art-item-right">next：<a href="/2017/10/09/Implement-Search-Auto-Complete-by-Python-Hadoop/" rel="next"  title="用Python在Hadoop上实现搜索自动补全">
						用Python在Hadoop上实现搜索自动补全
					</a><i class="icon icon-chevron-thin-right"></i></span>
                                            
                            </div>
                            
            </section>
            
                <section id="comments">
                    <div id="disqus_thread"></div>

                    <noscript>Please enable JavaScript to view the <a href="https://disqus.com/?ref_noscript">comments powered by Disqus.</a></noscript>
                </section>
                
    
</article>
<script>
    window.subData = {
        title: 'Selenium和BeautifulSoup的简单应用：爬取Pythonbooks.org',
        tools: true
    }

</script>

      </div>
      <aside class='l_side'>
        
  <section class='m_widget about'>
    
        <img class='avatar waves-image' src='/images/avatar.png' />
        
            <div class='header'>
                Yuan Zhang
            </div>
            <div class='content'>
                <div class='desc'>
                    Information -&gt; Knowledge -&gt; Wisdom
                </div>
            </div>
</section>


  <section class='m_widget links'>
<div class='header'>Links</div>
<div class='content'>
    <ul class="entry">
    
    </ul>
</div>
</section>

  <section class='m_widget categories'>
<div class='header'>Categories</div>
<div class='content'>
    
    <ul class="entry">
    
        <li><a class="flat-box" href="/categories/Big-Data/"><div class='name'>Big Data</div><div class='badget'>2</div></a></li>
    
        <li><a class="flat-box" href="/categories/Data-analysis/"><div class='name'>Data analysis</div><div class='badget'>1</div></a></li>
    
        <li><a class="flat-box" href="/categories/Web-Application/"><div class='name'>Web Application</div><div class='badget'>1</div></a></li>
    
        <li><a class="flat-box" href="/categories/general/"><div class='name'>general</div><div class='badget'>2</div></a></li>
    
    </ul>
    
</div>
</section>

  
<div class="m_widget tagcloud">
    <div class="header">Tags</div>
    <div class='content'>
        <a href="/tags/BeautifulSoup/" style="font-size: 14px; color: #808080">BeautifulSoup</a> <a href="/tags/Blog/" style="font-size: 14px; color: #808080">Blog</a> <a href="/tags/Data-analysis/" style="font-size: 14px; color: #808080">Data analysis</a> <a href="/tags/Docker/" style="font-size: 14px; color: #808080">Docker</a> <a href="/tags/First/" style="font-size: 14px; color: #808080">First</a> <a href="/tags/Hadoop/" style="font-size: 17px; color: #404040">Hadoop</a> <a href="/tags/Heroku/" style="font-size: 14px; color: #808080">Heroku</a> <a href="/tags/MapReduce/" style="font-size: 17px; color: #404040">MapReduce</a> <a href="/tags/Netlify/" style="font-size: 14px; color: #808080">Netlify</a> <a href="/tags/Pandas/" style="font-size: 14px; color: #808080">Pandas</a> <a href="/tags/Python/" style="font-size: 20px; color: #000">Python</a> <a href="/tags/Selenium/" style="font-size: 14px; color: #808080">Selenium</a> <a href="/tags/crawler/" style="font-size: 14px; color: #808080">crawler</a> <a href="/tags/migrate/" style="font-size: 14px; color: #808080">migrate</a> <a href="/tags/static-site/" style="font-size: 14px; color: #808080">static site</a>
    </div>
</div>



      </aside>
      <script>setLoadingBarProgress(60);</script>
    </div>
  </div>
  <footer id="footer" class="clearfix">

	<div class="social-wrapper">
  	
      
        <a href="https://github.com/rocheers" class="social github"
          target="_blank" rel="external">
          <span class="icon icon-github"></span>
        </a>
      
        <a href="https://twitter.com/rocheers" class="social twitter"
          target="_blank" rel="external">
          <span class="icon icon-twitter"></span>
        </a>
      
        <a href="/atom.xml" class="social rss"
          target="_blank" rel="external">
          <span class="icon icon-rss"></span>
        </a>
      
    
  </div>
  
<!--  <div>Theme <a href='https://github.com/stkevintan/hexo-theme-material-flow' class="codename">MaterialFlow</a> designed by <a href="http://keyin.me/" target="_blank">Kevin Tan</a>.</div>-->
  
</footer>


  <script>setLoadingBarProgress(80);</script>
  
    <script>
        var disqus_shortname = 'yuanhome';
        
            var disqus_config = function () {
                this.page.url = 'http://yuannow.com/2017/11/06/Python-Books-Crawler/';
                this.page.identifier = '_posts/Python-Books-Crawler.md';
            };
        
        (function() { // DON'T EDIT BELOW THIS LINE
            var d = document,
                s = d.createElement('script');
            s.src = "//yuanhome.disqus.com/embed.js";
            s.setAttribute('data-timestamp', +new Date());
            (d.head || d.body).appendChild(s);
        })();

    </script>

    <script id="dsq-count-scr" src="//yuanhome.disqus.com/count.js" async></script>


<script src="//apps.bdimg.com/libs/jquery/2.1.4/jquery.min.js"></script>
<script src='//cdn.bootcss.com/node-waves/0.7.5/waves.min.js'></script>
<script src="//cdn.bootcss.com/scrollReveal.js/3.3.2/scrollreveal.min.js"></script>
<script src="/js/jquery.fitvids.js"></script>
    <script>
        var GOOGLE_CUSTOM_SEARCH_API_KEY = "";
        var GOOGLE_CUSTOM_SEARCH_ENGINE_ID = "";
        var ALGOLIA_API_KEY = "";
        var ALGOLIA_APP_ID = "";
        var ALGOLIA_INDEX_NAME = "";
        var AZURE_SERVICE_NAME = "";
        var AZURE_INDEX_NAME = "";
        var AZURE_QUERY_KEY = "";
        var BAIDU_API_ID = "";
        var SEARCH_SERVICE = "hexo";
        var ROOT = "/" || "/";
        if (!ROOT.endsWith('/')) ROOT += '/';

    </script>
<script src="/js/search.js"></script>
<script src="/js/app.js"></script>

  <script>setLoadingBarProgress(100);</script>
<script type="text/x-mathjax-config">
    MathJax.Hub.Config({
        tex2jax: {
            inlineMath: [ ["$","$"], ["\\(","\\)"] ],
            skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code'],
            processEscapes: true
        }
    });
    MathJax.Hub.Queue(function() {
        var all = MathJax.Hub.getAllJax();
        for (var i = 0; i < all.length; ++i)
            all[i].SourceElement().parentNode.className += ' has-jax';
    });
</script>
<script src="http://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>
</body>
</html>
