<!DOCTYPE html>












  


<html class="theme-next mist use-motion" lang="en-US">
<head>
  <meta charset="UTF-8"/>
<meta http-equiv="X-UA-Compatible" content="IE=edge" />
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=2"/>
<meta name="theme-color" content="#222">



  
  
  <link rel="stylesheet" href="/lib/needsharebutton/needsharebutton.css">










<meta http-equiv="Cache-Control" content="no-transform" />
<meta http-equiv="Cache-Control" content="no-siteapp" />



  <meta name="google-site-verification" content="IT-JgWFnFLd6Jea67nuP0c1PiA5pLSFhdd1mbZptgUk" />














  
  
  <link href="/lib/fancybox/source/jquery.fancybox.css?v=2.1.5" rel="stylesheet" type="text/css" />







<link href="/lib/font-awesome/css/font-awesome.min.css?v=4.6.2" rel="stylesheet" type="text/css" />

<link href="/css/main.css?v=6.3.0" rel="stylesheet" type="text/css" />


  <link rel="apple-touch-icon" sizes="180x180" href="/uploads/apple-touch-icon.png?v=6.3.0">


  <link rel="icon" type="image/png" sizes="32x32" href="/uploads/favicon-32x32.png?v=6.3.0">


  <link rel="icon" type="image/png" sizes="16x16" href="/uploads/favicon-16x16.png?v=6.3.0">


  <link rel="mask-icon" href="/uploads/safari_pinned_tab.svg?v=6.3.0" color="#222">


  <link rel="manifest" href="/uploads/site.webmanifest.txt">


  <meta name="msapplication-config" content="/uploads/browserconfig.xml" />







<script type="text/javascript" id="hexo.configurations">
  var NexT = window.NexT || {};
  var CONFIG = {
    root: '/',
    scheme: 'Mist',
    version: '6.3.0',
    sidebar: {"position":"left","display":"post","offset":12,"b2t":false,"scrollpercent":false,"onmobile":false},
    fancybox: true,
    fastclick: false,
    lazyload: false,
    tabs: true,
    motion: {"enable":true,"async":false,"transition":{"post_block":"fadeIn","post_header":"slideDownIn","post_body":"slideDownIn","coll_header":"slideLeftIn","sidebar":"slideUpIn"}},
    algolia: {
      applicationID: '',
      apiKey: '',
      indexName: '',
      hits: {"per_page":10},
      labels: {"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}
    }
  };
</script>


  




  <meta name="description" content="记得很早的时候，刚开始接触搜索引擎，那时候Google还没有被墙，百度也是刚刚诞生没多久，无论我在输入框内输入什么，只是显示我输入的内容，并没有任何联想功能提示我接下来可能匹配的内容。有时候想找个东西，可就是死活想不起来准确的名字或者描述方式，这个时候搜索引擎也帮不了你，你只能变着法的尝试各种输入，来寻求最终你想要的结果。后来搜索引擎加入了联想功能，这着实是一大进步，极大地提高了搜索效率。有的时候">
<meta name="keywords" content="Hadoop,Python,MapReduce">
<meta property="og:type" content="article">
<meta property="og:title" content="用Python在Hadoop上实现搜索自动补全">
<meta property="og:url" content="https://yuannow.com/2017/10/09/Implement-Search-Auto-Complete-by-Python-Hadoop/index.html">
<meta property="og:site_name" content="XSpace">
<meta property="og:description" content="记得很早的时候，刚开始接触搜索引擎，那时候Google还没有被墙，百度也是刚刚诞生没多久，无论我在输入框内输入什么，只是显示我输入的内容，并没有任何联想功能提示我接下来可能匹配的内容。有时候想找个东西，可就是死活想不起来准确的名字或者描述方式，这个时候搜索引擎也帮不了你，你只能变着法的尝试各种输入，来寻求最终你想要的结果。后来搜索引擎加入了联想功能，这着实是一大进步，极大地提高了搜索效率。有的时候">
<meta property="og:locale" content="en-US">
<meta property="og:image" content="https://yuannow.com/images/autocomplete/autocomplete.png">
<meta property="og:image" content="https://yuannow.com/images/autocomplete/database.png">
<meta property="og:image" content="https://yuannow.com/images/autocomplete/ggif.gif">
<meta property="og:updated_time" content="2018-06-08T03:15:12.745Z">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="用Python在Hadoop上实现搜索自动补全">
<meta name="twitter:description" content="记得很早的时候，刚开始接触搜索引擎，那时候Google还没有被墙，百度也是刚刚诞生没多久，无论我在输入框内输入什么，只是显示我输入的内容，并没有任何联想功能提示我接下来可能匹配的内容。有时候想找个东西，可就是死活想不起来准确的名字或者描述方式，这个时候搜索引擎也帮不了你，你只能变着法的尝试各种输入，来寻求最终你想要的结果。后来搜索引擎加入了联想功能，这着实是一大进步，极大地提高了搜索效率。有的时候">
<meta name="twitter:image" content="https://yuannow.com/images/autocomplete/autocomplete.png">






  <link rel="canonical" href="https://yuannow.com/2017/10/09/Implement-Search-Auto-Complete-by-Python-Hadoop/"/>



<script type="text/javascript" id="page.configurations">
  CONFIG.page = {
    sidebar: "",
  };
</script>

  <title>用Python在Hadoop上实现搜索自动补全 | XSpace</title>
  




<script async src="https://www.googletagmanager.com/gtag/js?id=UA-107727758-1"></script>
<script>
  window.dataLayer = window.dataLayer || [];
  function gtag(){dataLayer.push(arguments);}
  gtag('js', new Date());

  gtag('config', 'UA-107727758-1');
</script>






  <noscript>
  <style type="text/css">
    .use-motion .motion-element,
    .use-motion .brand,
    .use-motion .menu-item,
    .sidebar-inner,
    .use-motion .post-block,
    .use-motion .pagination,
    .use-motion .comments,
    .use-motion .post-header,
    .use-motion .post-body,
    .use-motion .collection-title { opacity: initial; }

    .use-motion .logo,
    .use-motion .site-title,
    .use-motion .site-subtitle {
      opacity: initial;
      top: initial;
    }

    .use-motion {
      .logo-line-before i { left: initial; }
      .logo-line-after i { right: initial; }
    }
  </style>
</noscript>

</head>

<body itemscope itemtype="http://schema.org/WebPage" lang="en-US">

  
  
    
  

  <div class="container sidebar-position-left page-post-detail">
    <div class="headband"></div>

    <header id="header" class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-wrapper">
  <div class="site-meta ">
    

    <div class="custom-logo-site-title">
      <a href="/" class="brand" rel="start">
        <span class="logo-line-before"><i></i></span>
        <span class="site-title">XSpace</span>
        <span class="logo-line-after"><i></i></span>
      </a>
    </div>
    
      
        <p class="site-subtitle">Yuan Home</p>
      
    
  </div>

  <div class="site-nav-toggle">
    <button aria-label="Toggle navigation bar">
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
    </button>
  </div>
</div>



<nav class="site-nav">
  
    <ul id="menu" class="menu">
      
        
        
        
          
          <li class="menu-item menu-item-home">
    <a href="/" rel="section">
      <i class="menu-item-icon fa fa-fw fa-home"></i> <br />Home</a>
  </li>
        
        
        
          
          <li class="menu-item menu-item-about">
    <a href="/about/" rel="section">
      <i class="menu-item-icon fa fa-fw fa-user"></i> <br />About</a>
  </li>
        
        
        
          
          <li class="menu-item menu-item-archives">
    <a href="/archives/" rel="section">
      <i class="menu-item-icon fa fa-fw fa-archive"></i> <br />Archives</a>
  </li>

      
      
        <li class="menu-item menu-item-search">
          
            <a href="javascript:;" class="popup-trigger">
          
            
              <i class="menu-item-icon fa fa-search fa-fw"></i> <br />Search</a>
        </li>
      
    </ul>
  

  
    

  

  
    <div class="site-search">
      
  <div class="popup search-popup local-search-popup">
  <div class="local-search-header clearfix">
    <span class="search-icon">
      <i class="fa fa-search"></i>
    </span>
    <span class="popup-btn-close">
      <i class="fa fa-times-circle"></i>
    </span>
    <div class="local-search-input-wrapper">
      <input autocomplete="off"
             placeholder="Searching..." spellcheck="false"
             type="text" id="local-search-input">
    </div>
  </div>
  <div id="local-search-result"></div>
</div>



    </div>
  
</nav>



  



</div>
    </header>

    


    <main id="main" class="main">
      <div class="main-inner">
        <div class="content-wrap">
          
          <div id="content" class="content">
            

  <div id="posts" class="posts-expand">
    

  

  
  
  

  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="https://yuannow.com/2017/10/09/Implement-Search-Auto-Complete-by-Python-Hadoop/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="Yuan Zhang">
      <meta itemprop="description" content="Information -> Knowledge -> Wisdom">
      <meta itemprop="image" content="/uploads/avatar.jpg">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="XSpace">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">用Python在Hadoop上实现搜索自动补全
              
            
          </h1>
        

        <div class="post-meta">
          <span class="post-time">

            
            
            

            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">Posted on</span>
              

              
                
              

              <time title="Created: 2017-10-09 17:40:18" itemprop="dateCreated datePublished" datetime="2017-10-09T17:40:18-07:00">2017-10-09</time>
            

            
              

              
                
                <span class="post-meta-divider">|</span>
                

                <span class="post-meta-item-icon">
                  <i class="fa fa-calendar-check-o"></i>
                </span>
                
                  <span class="post-meta-item-text">Edited on</span>
                
                <time title="Modified: 2018-06-07 20:15:12" itemprop="dateModified" datetime="2018-06-07T20:15:12-07:00">2018-06-07</time>
              
            
          </span>

          
            <span class="post-category" >
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">In</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing"><a href="/categories/Big-Data/" itemprop="url" rel="index"><span itemprop="name">Big Data</span></a></span>

                
                
              
            </span>
          

          
            
              <span class="post-comments-count">
                <span class="post-meta-divider">|</span>
                <span class="post-meta-item-icon">
                  <i class="fa fa-comment-o"></i>
                </span>
                <a href="/2017/10/09/Implement-Search-Auto-Complete-by-Python-Hadoop/#comments" itemprop="discussionUrl">
                
                  <span class="post-comments-count disqus-comment-count"
                        data-disqus-identifier="2017/10/09/Implement-Search-Auto-Complete-by-Python-Hadoop/" itemprop="commentCount"></span>
                </a>
              </span>
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        <p><img src="/images/autocomplete/autocomplete.png" alt="search autocomplete"><br>记得很早的时候，刚开始接触搜索引擎，那时候Google还没有被墙，百度也是刚刚诞生没多久，无论我在输入框内输入什么，只是显示我输入的内容，并没有任何联想功能提示我接下来可能匹配的内容。有时候想找个东西，可就是死活想不起来准确的名字或者描述方式，这个时候搜索引擎也帮不了你，你只能变着法的尝试各种输入，来寻求最终你想要的结果。后来搜索引擎加入了联想功能，这着实是一大进步，极大地提高了搜索效率。有的时候，我们对于想查询的某一问题的提问方式是很模糊的，这个时候当你输入了一些关键词，发现搜索引擎会根据你的输入给你一些后续内容的建议，会让你更容易的找到自己想要的答案。</p>
<h1 id="本文目的"><a href="#本文目的" class="headerlink" title="本文目的"></a>本文目的</h1><p>上一篇我在《用Python在Hadoop上跑MapReduce》中介绍了一些关于如何利用<code>Hadoop Streaming</code>运行Python版MapReduce的简单操作，如何实现词频统计就像是MapReduce中的<em>Hello World</em>，不过做完了入门教程，为了深入学习，还得需要更多的练习。</p>
<p>在这篇文章中，我将会带各位实现一个很简单的搜索联想功能，比较粗糙，但是看起来也挺像那么回事的~</p>
<a id="more"></a>
<hr>
<h1 id="正文"><a href="#正文" class="headerlink" title="正文"></a>正文</h1><p>为了实现<code>autocomplete</code>，首先需要搞清楚它背后的原理，搜索引擎究竟是根据什么来给出提示的？比如我输入一个<code>autocomplete</code>之后，为什么后面推荐的是<em>python</em>，<em>algorithm</em>之类的，而不是<em>Naruto</em>，<em>One Piece</em>这些呢？</p>
<p>无论是百度还是谷歌，其实在大家用它们的搜索引擎收集你需要的信息的时候，它们也同样在收集信息。它们收集了大量的用户搜索的输入信息，同时还在抓取各种网页内容的信息，简单来说，搜索引擎通过某种算法将各种收集到的资料综合到一起，最终给出了一个输入联想的列表，这就是自动补全功能。</p>
<p>私下里作为学习MapReduce的项目，我们肯定不可能去试图实现真正的搜索引擎。不过做一个简陋版的，帮助自己理解<code>autocomplete</code>背后的实现原理，以及如何利用MapReduce来实现，也是足够的。</p>
<hr>
<h2 id="N-Gram"><a href="#N-Gram" class="headerlink" title="N-Gram"></a>N-Gram</h2><p>对于autocomplete背后实现的原理，很重要的一点就是N-Gram，<a href="http://blog.sciencenet.cn/blog-713101-797384.html" target="_blank" rel="noopener">这篇文章</a>有简明的介绍，举个例子好了：<code>implement search autocomplete in python</code></p>
<ul>
<li>这句话如果按2-Gram划分的话，就是<code>implement search</code>，<code>search autocomplete</code>，<code>autocomplete in</code>，<code>in python</code>；</li>
<li>那么按照3-Gram划分的话，就是<code>implement search autocomplete</code>，<code>search autocomplete in</code>，<code>autocomplete in python</code>；</li>
<li>按照4-Gram划分的话，就是<code>implement search autocomplete in</code>，<code>search autocomplete in python</code>；</li>
<li>按照5-Gram划分的话，就是一整句话，不作任何切割。</li>
</ul>
<p>这里我没有给出1-Gram的例子，各位可以思考一下是为什么，这里先卖个关子，下面会提到原因。这里我们先回头思考一下搜索引擎给出的联想词汇，比如我输入了一个<code>autocomplete</code>，那么后面你觉得是给出<code>in python</code>看上去更自然还是<code>Transformer</code>更合理？显然是前者对么，如果给出了后者，你可能会想：<code>autocomplete Transformer</code>是什么鬼？！难道是某种新型变形金刚么？没听过啊！那之所以会有这样的感觉，是因为从我们平时获取的信息中，我们对于<code>autocomplete</code>这个词后面的衔接词接收到的也是<code>in python</code>远远多于<code>Transformer</code>，对吧？所以说到这里就大概有点明晰了，搜索引擎对于联想词汇的推荐也有这方面的考虑，我们给输入一个或多个引导词，<code>autocomplete</code>功能将后面最有可能出现的几种选择展现给我们。所以这也是为什么用到N-Gram的原因，这里其实就是一个句子分割的过程。</p>
<p>那么这里就引出了下一个问题：是该基于一句话最后一个词来预测后面的推荐，还是根据更多的词甚至一整句来预测下面的出现呢？</p>
<p>还继续以上面的例子说好了。假设我已经输入了<code>implement search autocomplete in</code>，如果是按照最后一个出现的词来进行联想，那么<code>in</code>后面其实可以跟很多很多内容，都不会违和，对吧？比如<code>in box</code>，<code>in air</code>，<code>in heart</code>等等，但如果把这些联想放到一整句中，显然是不太合理的。因此，我们在实现<code>autocomplete</code>的时候，其实是<strong>基于N-Gram预测N-Gram</strong>。</p>
<p>那到这里，其实<code>autocomplete</code>的实现的大致思路就应该有了。我们需要将大批量的文档用N-Gram的处理方式进行切割，统计相同短语出现的频次，构建N-Gram的模型，然后找出每个短语之后出现频次最高的几个词汇作为预测保存下来。最终将结果存入数据库，以方便之后调用。下面我们就来看看如何一步步具体实现。</p>
<hr>
<h2 id="MapReduce实现"><a href="#MapReduce实现" class="headerlink" title="MapReduce实现"></a>MapReduce实现</h2><h3 id="N-Gram模型构建"><a href="#N-Gram模型构建" class="headerlink" title="N-Gram模型构建"></a>N-Gram模型构建</h3><p>在这次的代码实现中，我们需要用到两个mapper和reducer。首先，我们需要一对mapper和reducer将输入的文档进行切割。</p>
<p><code>n_gram_mapper.py</code></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> sys</span><br><span class="line"><span class="keyword">import</span> string</span><br><span class="line"><span class="keyword">import</span> re</span><br><span class="line">    </span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">main</span><span class="params">(N_Gram)</span>:</span></span><br><span class="line">    <span class="keyword">for</span> line <span class="keyword">in</span> sys.stdin:</span><br><span class="line">        <span class="comment"># 去除所有的标点符号</span></span><br><span class="line">        translator = str.maketrans(string.punctuation, <span class="string">" "</span> * len(string.punctuation))</span><br><span class="line">        line = line.translate(translator).strip().lower()</span><br><span class="line">        </span><br><span class="line">        <span class="comment"># 去除所有的数字</span></span><br><span class="line">        line = re.sub(<span class="string">"\d"</span>, <span class="string">" "</span>, line)</span><br><span class="line">        </span><br><span class="line">        <span class="comment"># 按照空格或者\t来切割</span></span><br><span class="line">        words = re.split(<span class="string">"\\s+"</span>, line)</span><br><span class="line">        <span class="keyword">if</span> len(words) &lt; <span class="number">2</span>:</span><br><span class="line">            <span class="keyword">continue</span></span><br><span class="line">            </span><br><span class="line">        <span class="keyword">for</span> i, word <span class="keyword">in</span> enumerate(words):</span><br><span class="line">            result = word</span><br><span class="line">            <span class="keyword">for</span> j, next_word <span class="keyword">in</span> enumerate(words[i+<span class="number">1</span>:], <span class="number">1</span>):</span><br><span class="line">                <span class="keyword">if</span> j &lt; N_Gram:</span><br><span class="line">                    result += <span class="string">" "</span></span><br><span class="line">                    result += next_word</span><br><span class="line">                    print(<span class="string">"&#123;&#125;\t&#123;&#125;"</span>.format(result, <span class="number">1</span>))</span><br><span class="line">                    </span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">'__main__'</span>:</span><br><span class="line">    main(<span class="number">5</span>)</span><br></pre></td></tr></table></figure>
<p>如果你想构建一个<strong>N=5</strong>的N-Gram模型，那么在mapper里，就需要将2到5的分割方式都输出。还记得上面我有留一个悬念，为什么不考虑1-Gram么？因为显然1-Gram是没有用的，它并不能告诉我一个短语后面可能出现的词有什么。</p>
<p><code>n_gram_reducer.py</code></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> sys</span><br><span class="line"><span class="keyword">from</span> itertools <span class="keyword">import</span> groupby</span><br><span class="line"><span class="keyword">from</span> operator <span class="keyword">import</span> itemgetter</span><br><span class="line">    </span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">parse_output</span><span class="params">(std_input)</span>:</span></span><br><span class="line">    <span class="comment"># 利用generator节省MapReduce内存使用空间</span></span><br><span class="line">    <span class="keyword">for</span> line <span class="keyword">in</span> std_input:</span><br><span class="line">        <span class="keyword">yield</span> line.strip().split(<span class="string">"\t"</span>)</span><br><span class="line">        </span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">main</span><span class="params">()</span>:</span></span><br><span class="line">    data = parse_output(sys.stdin)</span><br><span class="line">    <span class="keyword">for</span> word, group <span class="keyword">in</span> groupby(data, itemgetter(<span class="number">0</span>)):</span><br><span class="line">        <span class="keyword">try</span>:</span><br><span class="line">            total_count = sum(int(count) <span class="keyword">for</span> word, count <span class="keyword">in</span> group)</span><br><span class="line">            print(<span class="string">"&#123;&#125;\t&#123;&#125;"</span>.format(word, total_count))</span><br><span class="line">        <span class="keyword">except</span> ValueError:</span><br><span class="line">            <span class="keyword">continue</span></span><br><span class="line">            </span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">'__main__'</span>:</span><br><span class="line">    main()</span><br></pre></td></tr></table></figure>
<p>这回的reducer我用到了<code>generator</code>来调用数据，这样做可以有效节省内存占用空间。因为随着输入数据量的越来越大，即便是5-Gram，依然也是个很庞大的记录数量。下面的主函数部分，我也放弃了之前的简单用法，用groupby可以明显提升代码的阅读逻辑，对<code>itertools.groupby</code>不太熟悉的朋友可以看<a href="https://docs.python.org/3/library/itertools.html" target="_blank" rel="noopener">这份官方文档</a>。</p>
<h3 id="N-Gram测试结果"><a href="#N-Gram测试结果" class="headerlink" title="N-Gram测试结果"></a>N-Gram测试结果</h3><p>做下一步之前，我们先来本地测试一下这一对mapper和reducer是否好用。</p>
<p>测试文档：我直接把<a href="https://en.wikipedia.org/wiki/MapReduce" target="_blank" rel="noopener">MapReduce</a>的Wiki里头一段关于它的说明解释，粘贴下来作为测试文档用。<br><figure class="highlight console"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line">root@hadoop:~/src/p2py# cat input/file2.txt | ./n_gram_mapper.py | sort | ./n_gram_reducer.py</span><br><span class="line">a cluster	1</span><br><span class="line">a good	1</span><br><span class="line">a good mapreduce	1</span><br><span class="line">a good mapreduce algorithm	1</span><br><span class="line">a map	1</span><br><span class="line">a map procedure	1</span><br><span class="line">a map procedure method	1</span><br><span class="line">a map procedure method that	1</span><br><span class="line">a mapreduce	1</span><br><span class="line">a mapreduce program	1</span><br><span class="line">a mapreduce program is	1</span><br><span class="line">a mapreduce program is composed	1</span><br><span class="line">...</span><br><span class="line">and reduce	3</span><br><span class="line">and reduce capabilities	1</span><br><span class="line">and reduce functions	2</span><br><span class="line">...</span><br><span class="line">map and	3</span><br><span class="line">map and reduce	3</span><br><span class="line">map and reduce capabilities	1</span><br><span class="line">map and reduce functions	2</span><br><span class="line">...</span><br></pre></td></tr></table></figure></p>
<p>我这里就截取一部分结果，实在太长了……</p>
<h3 id="构建预测概率的模型"><a href="#构建预测概率的模型" class="headerlink" title="构建预测概率的模型"></a>构建预测概率的模型</h3><p>我们现在已经有了N-Gram切割后的结果了，下一步就是要在此基础上分析每一个词汇或者短语后面可能出现的内容，这里其实可以理解成构建一个概率模型，很简单一个概率模型。</p>
<p>举例说明，我们先来看刚才的结果生成的一部分<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">and data	1</span><br><span class="line">and development	1</span><br><span class="line">and fault	3</span><br><span class="line">and generating	1</span><br><span class="line">and less	1</span><br><span class="line">and providing	1</span><br><span class="line">and reduce	3</span><br><span class="line">and scatter	1</span><br><span class="line">and sorting	1</span><br></pre></td></tr></table></figure></p>
<p>先仅仅分析and之后可能出现的词汇，所有的情况都在这里摆着了。那这时候autocomplete会如何给出推荐呢？很显然的，fault和reduce会放到头两个推荐对吧，为什么？这其实就是个概率的问题：and后接一个词在文中出现了<code>1+1+3+1+1+1+3+1+1=13</code>次，那fault和reduce推荐的概率就是<code>3/13</code>，剩下的所有都是<code>1/13</code>的概率。对于<code>autocomplete</code>系统来说，这意味着当用户输入了and之后，它认为用户更有可能继续输入的是fault和reduce，因为从它以往经验（系统所得到的输入）来看，fault和reduce出现的频次更多一些，相比较于其他的结果。因此，下一步工作，我们需要得到一个类似于<code>and&lt;\t&gt;data=1</code>这样的数据记录样式，来统计所有的短语之后跟随的词汇以及它出现的频次。这里我们之所以不用概率来进行记录，是因为从刚才的计算过程来看，词频和概率是正相关的，那么就没必要多算一步记录概率了。</p>
<p><code>prob_mapper.py</code></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> sys</span><br><span class="line"><span class="keyword">import</span> string</span><br><span class="line">    </span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">main</span><span class="params">(threshold)</span>:</span></span><br><span class="line">    <span class="keyword">for</span> line <span class="keyword">in</span> sys.stdin:</span><br><span class="line">        words_phrase, count = line.strip().split(<span class="string">"\t"</span>)</span><br><span class="line">        <span class="keyword">if</span> int(count) &lt; threshold:</span><br><span class="line">            <span class="keyword">continue</span></span><br><span class="line">            </span><br><span class="line">        words = words_phrase.strip().split(<span class="string">" "</span>)</span><br><span class="line">        <span class="keyword">if</span> len(words) &lt; <span class="number">2</span>:</span><br><span class="line">            <span class="keyword">continue</span></span><br><span class="line">            </span><br><span class="line">        print(<span class="string">"&#123;&#125;\t&#123;&#125;"</span>.format(<span class="string">' '</span>.join(words[:<span class="number">-1</span>]), words[<span class="number">-1</span>] + <span class="string">"="</span> + count))</span><br><span class="line">        </span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">'__main__'</span>:</span><br><span class="line">    main(<span class="number">2</span>)</span><br></pre></td></tr></table></figure>
<p>mapper的工作其实很简单，基本没有什么需要说明的。需要注意的是，这里我加入了一个threshold参数，意义是为了筛选掉一部分出现频次太低的结果。刚才举的例子里，每个结果出现的频次其实都不高，这样threshold肯定是没用的，但实际生产中，比如像Google和百度这样的超大规模的搜索引擎，每天可能抓取的数据量十分庞大。事实上，我们每次在搜索框中输入内容，得到的联想其实都在二十条以内，一般来说不会给太多的，太多的话，用户筛选起来也是个麻烦。那对于那些基本很少出现的词组组合，也就没必要存储下来，被搜索到的概率太低，如果全部都记录下来，对数据库的存储容量是个很大的负担。</p>
<p><code>prob_reducer.py</code></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> sys</span><br><span class="line"><span class="keyword">from</span> itertools <span class="keyword">import</span> groupby</span><br><span class="line"><span class="keyword">from</span> operator <span class="keyword">import</span> itemgetter</span><br><span class="line">    </span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">parse_output</span><span class="params">(std_input)</span>:</span></span><br><span class="line">    <span class="keyword">for</span> line <span class="keyword">in</span> std_input:</span><br><span class="line">        <span class="keyword">yield</span> line.strip().split(<span class="string">"\t"</span>)</span><br><span class="line">        </span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">main</span><span class="params">(n_gram)</span>:</span></span><br><span class="line">    data = parse_output(sys.stdin)</span><br><span class="line">    <span class="keyword">for</span> starting_phrase, group <span class="keyword">in</span> groupby(data, itemgetter(<span class="number">0</span>)):</span><br><span class="line">        result = &#123;&#125;</span><br><span class="line">        <span class="keyword">for</span> _, word_count <span class="keyword">in</span> group:</span><br><span class="line">            word, count = word_count.split(<span class="string">"="</span>)</span><br><span class="line">            count = int(count)</span><br><span class="line">            <span class="keyword">if</span> count <span class="keyword">not</span> <span class="keyword">in</span> result:</span><br><span class="line">                result[count] = []</span><br><span class="line">            result[count].append(word)</span><br><span class="line">            </span><br><span class="line">        i = <span class="number">0</span></span><br><span class="line">        <span class="keyword">for</span> key, value <span class="keyword">in</span> result.items():</span><br><span class="line">            <span class="keyword">if</span> i &lt; n_gram:</span><br><span class="line">                <span class="keyword">for</span> word <span class="keyword">in</span> value:</span><br><span class="line">                    print(<span class="string">"&#123;&#125;,&#123;&#125;,&#123;&#125;"</span>.format(starting_phrase, word, key))</span><br><span class="line">                    i += <span class="number">1</span></span><br><span class="line">                    </span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">'__main__'</span>:</span><br><span class="line">    main(<span class="number">4</span>)</span><br></pre></td></tr></table></figure>
<p><code>starting_phrase</code>代表的是用户输入的部分，<code>following_word</code>代表的是后面可能出现的词汇，<code>count</code>顾名思义就是指词频了。在reducer中，我们先按照词频的不同将可能出现的词汇分组放置，然后再根据我们需要的N-Gram大小来依次输出。这里的参数n_gram和之前n_gram_mapper里的n_gram意思一样，但取值可以不同。</p>
<hr>
<h3 id="预测概率的测试结果"><a href="#预测概率的测试结果" class="headerlink" title="预测概率的测试结果"></a>预测概率的测试结果</h3><p>下面我们来看看本地测试结果吧，就用上一步n_gram_reducer得出的结果继续操作。</p>
<figure class="highlight console"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br></pre></td><td class="code"><pre><span class="line">root@hadoop:~/src/p2py# cat result.txt | ./prob_mapper.py | ./prob_reducer.py </span><br><span class="line">and,fault,3</span><br><span class="line">and fault,tolerance,3</span><br><span class="line">and,reduce,3</span><br><span class="line">and reduce,functions,2</span><br><span class="line">big,data,2</span><br><span class="line">communication,cost,2</span><br><span class="line">fault,tolerance,3</span><br><span class="line">is,a,2</span><br><span class="line">map,and,3</span><br><span class="line">map and,reduce,3</span><br><span class="line">map and reduce,functions,2</span><br><span class="line">mapreduce,framework,3</span><br><span class="line">method,that,2</span><br><span class="line">method that,performs,2</span><br><span class="line">model,and,2</span><br><span class="line">model,is,2</span><br><span class="line">not,the,2</span><br><span class="line">of,the,4</span><br><span class="line">of the,mapreduce,2</span><br><span class="line">of the mapreduce,framework,2</span><br><span class="line">optimizing,the,2</span><br><span class="line">reduce,functions,2</span><br><span class="line">such,as,2</span><br><span class="line">that,performs,2</span><br><span class="line">the,mapreduce,4</span><br><span class="line">the mapreduce,framework,3</span><br><span class="line">the,various,2</span><br></pre></td></tr></table></figure>
<p>因为之前在mapper里我们将threshold设置为2，这里我们就可以看到结果中只有词频不小于2次的。</p>
<h3 id="运行在Hadoop上"><a href="#运行在Hadoop上" class="headerlink" title="运行在Hadoop上"></a>运行在Hadoop上</h3><p>刚才在本地跑过了之后，下面来进行Hadoop上的测试。为了方便快捷，我编写了一个script来运行两对mapper和reducer，最后把得到的数据从HDFS里导出到本地。<br><figure class="highlight console"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></td><td class="code"><pre><span class="line">root@hadoop:~/src/p2py# ./run_script.sh </span><br><span class="line">    </span><br><span class="line">Cleaning old results in /output...</span><br><span class="line">17/10/10 01:30:20 INFO fs.TrashPolicyDefault: Namenode trash configuration: Deletion interval = 0 minutes, Emptier interval = 0 minutes.</span><br><span class="line">Deleted /output</span><br><span class="line">    </span><br><span class="line">Running python in Hadoop by hadoop streaming...</span><br><span class="line">    </span><br><span class="line">packageJobJar: [/tmp/hadoop-unjar5398292596529368576/] [] /tmp/streamjob5913697815224381390.jar tmpDir=null</span><br><span class="line">17/10/10 01:30:22 INFO client.RMProxy: Connecting to ResourceManager at hadoop-master/172.18.0.2:8032</span><br><span class="line">17/10/10 01:30:22 INFO client.RMProxy: Connecting to ResourceManager at hadoop-master/172.18.0.2:8032</span><br><span class="line">17/10/10 01:30:23 INFO mapred.FileInputFormat: Total input paths to process : 1</span><br><span class="line">...</span><br><span class="line">17/10/10 01:30:49 INFO streaming.StreamJob: Output directory: /output/first</span><br><span class="line">    </span><br><span class="line">Running 2nd mapper and reducer...</span><br><span class="line">    </span><br><span class="line">packageJobJar: [/tmp/hadoop-unjar6814698868258273333/] [] /tmp/streamjob6470458846508985375.jar tmpDir=null</span><br><span class="line">17/10/10 01:30:51 INFO client.RMProxy: Connecting to ResourceManager at hadoop-master/172.18.0.2:8032</span><br><span class="line">17/10/10 01:30:51 INFO client.RMProxy: Connecting to ResourceManager at hadoop-master/172.18.0.2:8032</span><br><span class="line">17/10/10 01:30:52 INFO mapred.FileInputFormat: Total input paths to process : 1</span><br><span class="line">...</span><br><span class="line">17/10/10 01:31:13 INFO streaming.StreamJob: Output directory: /output/second</span><br><span class="line">    </span><br><span class="line">Moving outputs from HDFS to local...</span><br><span class="line">    </span><br><span class="line">Got the output!</span><br></pre></td></tr></table></figure></p>
<p>一切顺利运行！最终结果也被成功导出到本地。</p>
<hr>
<h2 id="导入数据库"><a href="#导入数据库" class="headerlink" title="导入数据库"></a>导入数据库</h2><p>其实到上一小节，MapReduce的工作就都做完了，但为了让<code>autocomplete</code>可以展现出应有的效果，这里还需要将刚才生成的数据导出到数据库中，以便之后和Web结合来体现功能。</p>
<p>数据库我用的是MySQL，大家可以任意选择。下面是我的数据库操作代码：<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> sys</span><br><span class="line"><span class="keyword">import</span> MySQLdb <span class="keyword">as</span> mdb</span><br><span class="line">    </span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">read_data</span><span class="params">(file)</span>:</span></span><br><span class="line">    <span class="keyword">for</span> line <span class="keyword">in</span> file.readlines():</span><br><span class="line">        <span class="keyword">yield</span> line.strip().split(<span class="string">","</span>)</span><br><span class="line">        </span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">main</span><span class="params">(input_data)</span>:</span></span><br><span class="line">    <span class="keyword">with</span> mdb.connect(<span class="string">'localhost'</span>, <span class="string">'username'</span>, <span class="string">'password'</span>, <span class="string">'dbname'</span>) <span class="keyword">as</span> cur:</span><br><span class="line">        cur.execute(<span class="string">"DROP TABLE IF EXISTS output"</span>)</span><br><span class="line">        cur.execute(</span><br><span class="line">            <span class="string">"CREATE TABLE output(starting_phrase VARCHAR(250), following_word VARCHAR(250), count INT)"</span>)</span><br><span class="line">        <span class="keyword">with</span> open(input_data, <span class="string">'r'</span>) <span class="keyword">as</span> file:</span><br><span class="line">            <span class="keyword">for</span> starting_phrase, following_word, count <span class="keyword">in</span> read_data(file):</span><br><span class="line">                cur.execute(</span><br><span class="line">                    <span class="string">"INSERT INTO output(starting_phrase, following_word, count) \</span></span><br><span class="line"><span class="string">                     VALUES('&#123;&#125;', '&#123;&#125;', &#123;&#125;)"</span>.format(starting_phrase, following_word, count))</span><br><span class="line">                     </span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">'__main__'</span>:</span><br><span class="line">    main(<span class="string">"output"</span>)</span><br></pre></td></tr></table></figure></p>
<p>数据库中显示的结果：<br><img src="/images/autocomplete/database.png" alt="database"></p>
<hr>
<h2 id="展示结果"><a href="#展示结果" class="headerlink" title="展示结果"></a>展示结果</h2><p>我简单做了一个Web展示的页面，基于Ajax和PHP，连接数据库后，测试结果如下图所示：<br><img src="/images/autocomplete/ggif.gif" alt="test"></p>
<hr>
<h1 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h1><p>本文从零开始，不太详细的介绍了<code>autocomplete</code>的工作原理，以及如何利用Python和MapReduce来处理数据。相比较Java实现这些内容而言，Python确实需要注意更多的细节，毕竟Java是Hadoop原生环境，configuration的配置真的是方便。之前做wordcount时没有觉得Python+Hadoop Streaming的方式有什么问题，因为Python天生的简洁特质，感觉比Java啰里啰嗦的舒服多了。但这次的代码实现上就看出端倪了，Python下更多的细节部分需要开发者自己写代码去维护，就像不同的mapper，reducer之间的数据传输，还有输出到数据库保存。</p>
<p>一路从头看到这里的朋友，感谢你的阅读，如果有疑惑，欢迎👇下面留言，如果文章中有什么不对的地方，也欢迎批评和指正。</p>
<hr>
<h1 id="Related-Links"><a href="#Related-Links" class="headerlink" title="Related Links"></a>Related Links</h1><ol>
<li><a href="http://blog.sciencenet.cn/blog-713101-797384.html" target="_blank" rel="noopener">N-gram的原理、用途和研究</a></li>
</ol>

      
    </div>

    

    
    
    

    

    

    

    <footer class="post-footer">
      
        <div class="post-tags">
          
            <a href="/tags/Hadoop/" rel="tag"># Hadoop</a>
          
            <a href="/tags/Python/" rel="tag"># Python</a>
          
            <a href="/tags/MapReduce/" rel="tag"># MapReduce</a>
          
        </div>
      

      
      
      

      
        <div class="post-nav">
          <div class="post-nav-next post-nav-item">
            
              <a href="/2017/10/02/Data-analysis-in-Python-by-Pandas/" rel="next" title="Data analysis in Python by Pandas">
                <i class="fa fa-chevron-left"></i> Data analysis in Python by Pandas
              </a>
            
          </div>

          <span class="post-nav-divider"></span>

          <div class="post-nav-prev post-nav-item">
            
              <a href="/2017/11/06/Python-Books-Crawler/" rel="prev" title="Selenium和BeautifulSoup的简单应用：爬取Pythonbooks.org">
                Selenium和BeautifulSoup的简单应用：爬取Pythonbooks.org <i class="fa fa-chevron-right"></i>
              </a>
            
          </div>
        </div>
      

      
      
    </footer>
  </div>
  
  
  
  </article>



    <div class="post-spread">
      
    </div>
  </div>


          </div>
          

  
    <div class="comments" id="comments">
      <div id="disqus_thread">
        <noscript>
          Please enable JavaScript to view the
          <a href="https://disqus.com/?ref_noscript">comments powered by Disqus.</a>
        </noscript>
      </div>
    </div>

  



        </div>
        
          
  
  <div class="sidebar-toggle">
    <div class="sidebar-toggle-line-wrap">
      <span class="sidebar-toggle-line sidebar-toggle-line-first"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-middle"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-last"></span>
    </div>
  </div>

  <aside id="sidebar" class="sidebar">
    
    <div class="sidebar-inner">

      

      
        <ul class="sidebar-nav motion-element">
          <li class="sidebar-nav-toc sidebar-nav-active" data-target="post-toc-wrap">
            Table of Contents
          </li>
          <li class="sidebar-nav-overview" data-target="site-overview-wrap">
            Overview
          </li>
        </ul>
      

      <section class="site-overview-wrap sidebar-panel">
        <div class="site-overview">
          <div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person">
            
              <img class="site-author-image" itemprop="image"
                src="/uploads/avatar.jpg"
                alt="Yuan Zhang" />
            
              <p class="site-author-name" itemprop="name">Yuan Zhang</p>
              <p class="site-description motion-element" itemprop="description">Information -> Knowledge -> Wisdom</p>
          </div>

          
            <nav class="site-state motion-element">
              
                <div class="site-state-item site-state-posts">
                
                  <a href="/archives/">
                
                    <span class="site-state-item-count">6</span>
                    <span class="site-state-item-name">posts</span>
                  </a>
                </div>
              

              
                
                
                <div class="site-state-item site-state-categories">
                  
                    
                    
                      
                    
                      
                    
                      
                    
                      
                    
                    <span class="site-state-item-count">4</span>
                    <span class="site-state-item-name">categories</span>
                  
                </div>
              

              
                
                
                <div class="site-state-item site-state-tags">
                  
                    
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                    <span class="site-state-item-count">15</span>
                    <span class="site-state-item-name">tags</span>
                  
                </div>
              
            </nav>
          

          

          
            <div class="links-of-author motion-element">
              
                <span class="links-of-author-item">
                  <a href="https://github.com/rocheers" target="_blank" title="GitHub"><i class="fa fa-fw fa-github"></i></a>
                  
                </span>
              
                <span class="links-of-author-item">
                  <a href="mailto:rocheers@gmail.com" target="_blank" title="E-Mail"><i class="fa fa-fw fa-envelope"></i></a>
                  
                </span>
              
            </div>
          

          
          

          
          

          
            
          
          

        </div>
      </section>

      
      <!--noindex-->
        <section class="post-toc-wrap motion-element sidebar-panel sidebar-panel-active">
          <div class="post-toc">

            
              
            

            
              <div class="post-toc-content"><ol class="nav"><li class="nav-item nav-level-1"><a class="nav-link" href="#本文目的"><span class="nav-number">1.</span> <span class="nav-text">本文目的</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#正文"><span class="nav-number">2.</span> <span class="nav-text">正文</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#N-Gram"><span class="nav-number">2.1.</span> <span class="nav-text">N-Gram</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#MapReduce实现"><span class="nav-number">2.2.</span> <span class="nav-text">MapReduce实现</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#N-Gram模型构建"><span class="nav-number">2.2.1.</span> <span class="nav-text">N-Gram模型构建</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#N-Gram测试结果"><span class="nav-number">2.2.2.</span> <span class="nav-text">N-Gram测试结果</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#构建预测概率的模型"><span class="nav-number">2.2.3.</span> <span class="nav-text">构建预测概率的模型</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#预测概率的测试结果"><span class="nav-number">2.2.4.</span> <span class="nav-text">预测概率的测试结果</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#运行在Hadoop上"><span class="nav-number">2.2.5.</span> <span class="nav-text">运行在Hadoop上</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#导入数据库"><span class="nav-number">2.3.</span> <span class="nav-text">导入数据库</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#展示结果"><span class="nav-number">2.4.</span> <span class="nav-text">展示结果</span></a></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#总结"><span class="nav-number">3.</span> <span class="nav-text">总结</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#Related-Links"><span class="nav-number">4.</span> <span class="nav-text">Related Links</span></a></li></ol></div>
            

          </div>
        </section>
      <!--/noindex-->
      

      

    </div>
  </aside>


        
      </div>
    </main>

    <footer id="footer" class="footer">
      <div class="footer-inner">
        <div class="copyright">&copy; 2017 &mdash; <span itemprop="copyrightYear">2018</span>
  <span class="with-love" id="animate">
    <i class="fa fa-user-circle"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">Yuan Zhang</span>

  

  
</div>




  <div class="powered-by">Powered by <a class="theme-link" target="_blank" href="https://hexo.io">Hexo</a> v3.7.1</div>



  <span class="post-meta-divider">|</span>



  <div class="theme-info">Theme &mdash; <a class="theme-link" target="_blank" href="https://github.com/theme-next/hexo-theme-next">NexT.Mist</a> v6.3.0</div>




        








        
      </div>
    </footer>

    
      <div class="back-to-top">
        <i class="fa fa-arrow-up"></i>
        
      </div>
    

    
      <div id="needsharebutton-float">
        <span class="btn">
          <i class="fa fa-share-alt" aria-hidden="true"></i>
        </span>
      </div>
    

  </div>

  

<script type="text/javascript">
  if (Object.prototype.toString.call(window.Promise) !== '[object Function]') {
    window.Promise = null;
  }
</script>












  















  
  
    <script type="text/javascript" src="/lib/jquery/index.js?v=2.1.3"></script>
  

  
  
    <script type="text/javascript" src="/lib/velocity/velocity.min.js?v=1.2.1"></script>
  

  
  
    <script type="text/javascript" src="/lib/velocity/velocity.ui.min.js?v=1.2.1"></script>
  

  
  
    <script type="text/javascript" src="/lib/fancybox/source/jquery.fancybox.pack.js?v=2.1.5"></script>
  


  


  <script type="text/javascript" src="/js/src/utils.js?v=6.3.0"></script>

  <script type="text/javascript" src="/js/src/motion.js?v=6.3.0"></script>



  
  

  
  <script type="text/javascript" src="/js/src/scrollspy.js?v=6.3.0"></script>
<script type="text/javascript" src="/js/src/post-details.js?v=6.3.0"></script>



  


  <script type="text/javascript" src="/js/src/bootstrap.js?v=6.3.0"></script>



  

  
    <script id="dsq-count-scr" src="https://yuanhome.disqus.com/count.js" async></script>
  

  
    <script type="text/javascript">
      var disqus_config = function () {
        this.page.url = 'https://yuannow.com/2017/10/09/Implement-Search-Auto-Complete-by-Python-Hadoop/';
        this.page.identifier = '2017/10/09/Implement-Search-Auto-Complete-by-Python-Hadoop/';
        this.page.title = '用Python在Hadoop上实现搜索自动补全';
        };
      function loadComments () {
        var d = document, s = d.createElement('script');
        s.src = 'https://yuanhome.disqus.com/embed.js';
        s.setAttribute('data-timestamp', '' + +new Date());
        (d.head || d.body).appendChild(s);
      }
      
        $(function () {
          var offsetTop = $('#comments').offset().top - $(window).height();
          if (offsetTop <= 0) {
            // load directly when there's no a scrollbar
            loadComments();
          } else {
            $(window).on('scroll.disqus_scroll', function () {
              var scrollTop = document.documentElement.scrollTop;
              if (scrollTop >= offsetTop) {
                $(window).off('.disqus_scroll');
                loadComments();
              }
            });
          }
        });
      
    </script>
  





	





  












  

  <script type="text/javascript">
    // Popup Window;
    var isfetched = false;
    var isXml = true;
    // Search DB path;
    var search_path = "search.xml";
    if (search_path.length === 0) {
      search_path = "search.xml";
    } else if (/json$/i.test(search_path)) {
      isXml = false;
    }
    var path = "/" + search_path;
    // monitor main search box;

    var onPopupClose = function (e) {
      $('.popup').hide();
      $('#local-search-input').val('');
      $('.search-result-list').remove();
      $('#no-result').remove();
      $(".local-search-pop-overlay").remove();
      $('body').css('overflow', '');
    }

    function proceedsearch() {
      $("body")
        .append('<div class="search-popup-overlay local-search-pop-overlay"></div>')
        .css('overflow', 'hidden');
      $('.search-popup-overlay').click(onPopupClose);
      $('.popup').toggle();
      var $localSearchInput = $('#local-search-input');
      $localSearchInput.attr("autocapitalize", "none");
      $localSearchInput.attr("autocorrect", "off");
      $localSearchInput.focus();
    }

    // search function;
    var searchFunc = function(path, search_id, content_id) {
      'use strict';

      // start loading animation
      $("body")
        .append('<div class="search-popup-overlay local-search-pop-overlay">' +
          '<div id="search-loading-icon">' +
          '<i class="fa fa-spinner fa-pulse fa-5x fa-fw"></i>' +
          '</div>' +
          '</div>')
        .css('overflow', 'hidden');
      $("#search-loading-icon").css('margin', '20% auto 0 auto').css('text-align', 'center');

      

      $.ajax({
        url: path,
        dataType: isXml ? "xml" : "json",
        async: true,
        success: function(res) {
          // get the contents from search data
          isfetched = true;
          $('.popup').detach().appendTo('.header-inner');
          var datas = isXml ? $("entry", res).map(function() {
            return {
              title: $("title", this).text(),
              content: $("content",this).text(),
              url: $("url" , this).text()
            };
          }).get() : res;
          var input = document.getElementById(search_id);
          var resultContent = document.getElementById(content_id);
          var inputEventFunction = function() {
            var searchText = input.value.trim().toLowerCase();
            var keywords = searchText.split(/[\s\-]+/);
            if (keywords.length > 1) {
              keywords.push(searchText);
            }
            var resultItems = [];
            if (searchText.length > 0) {
              // perform local searching
              datas.forEach(function(data) {
                var isMatch = false;
                var hitCount = 0;
                var searchTextCount = 0;
                var title = data.title.trim();
                var titleInLowerCase = title.toLowerCase();
                var content = data.content.trim().replace(/<[^>]+>/g,"");
                
                var contentInLowerCase = content.toLowerCase();
                var articleUrl = decodeURIComponent(data.url);
                var indexOfTitle = [];
                var indexOfContent = [];
                // only match articles with not empty titles
                if(title != '') {
                  keywords.forEach(function(keyword) {
                    function getIndexByWord(word, text, caseSensitive) {
                      var wordLen = word.length;
                      if (wordLen === 0) {
                        return [];
                      }
                      var startPosition = 0, position = [], index = [];
                      if (!caseSensitive) {
                        text = text.toLowerCase();
                        word = word.toLowerCase();
                      }
                      while ((position = text.indexOf(word, startPosition)) > -1) {
                        index.push({position: position, word: word});
                        startPosition = position + wordLen;
                      }
                      return index;
                    }

                    indexOfTitle = indexOfTitle.concat(getIndexByWord(keyword, titleInLowerCase, false));
                    indexOfContent = indexOfContent.concat(getIndexByWord(keyword, contentInLowerCase, false));
                  });
                  if (indexOfTitle.length > 0 || indexOfContent.length > 0) {
                    isMatch = true;
                    hitCount = indexOfTitle.length + indexOfContent.length;
                  }
                }

                // show search results

                if (isMatch) {
                  // sort index by position of keyword

                  [indexOfTitle, indexOfContent].forEach(function (index) {
                    index.sort(function (itemLeft, itemRight) {
                      if (itemRight.position !== itemLeft.position) {
                        return itemRight.position - itemLeft.position;
                      } else {
                        return itemLeft.word.length - itemRight.word.length;
                      }
                    });
                  });

                  // merge hits into slices

                  function mergeIntoSlice(text, start, end, index) {
                    var item = index[index.length - 1];
                    var position = item.position;
                    var word = item.word;
                    var hits = [];
                    var searchTextCountInSlice = 0;
                    while (position + word.length <= end && index.length != 0) {
                      if (word === searchText) {
                        searchTextCountInSlice++;
                      }
                      hits.push({position: position, length: word.length});
                      var wordEnd = position + word.length;

                      // move to next position of hit

                      index.pop();
                      while (index.length != 0) {
                        item = index[index.length - 1];
                        position = item.position;
                        word = item.word;
                        if (wordEnd > position) {
                          index.pop();
                        } else {
                          break;
                        }
                      }
                    }
                    searchTextCount += searchTextCountInSlice;
                    return {
                      hits: hits,
                      start: start,
                      end: end,
                      searchTextCount: searchTextCountInSlice
                    };
                  }

                  var slicesOfTitle = [];
                  if (indexOfTitle.length != 0) {
                    slicesOfTitle.push(mergeIntoSlice(title, 0, title.length, indexOfTitle));
                  }

                  var slicesOfContent = [];
                  while (indexOfContent.length != 0) {
                    var item = indexOfContent[indexOfContent.length - 1];
                    var position = item.position;
                    var word = item.word;
                    // cut out 100 characters
                    var start = position - 20;
                    var end = position + 80;
                    if(start < 0){
                      start = 0;
                    }
                    if (end < position + word.length) {
                      end = position + word.length;
                    }
                    if(end > content.length){
                      end = content.length;
                    }
                    slicesOfContent.push(mergeIntoSlice(content, start, end, indexOfContent));
                  }

                  // sort slices in content by search text's count and hits' count

                  slicesOfContent.sort(function (sliceLeft, sliceRight) {
                    if (sliceLeft.searchTextCount !== sliceRight.searchTextCount) {
                      return sliceRight.searchTextCount - sliceLeft.searchTextCount;
                    } else if (sliceLeft.hits.length !== sliceRight.hits.length) {
                      return sliceRight.hits.length - sliceLeft.hits.length;
                    } else {
                      return sliceLeft.start - sliceRight.start;
                    }
                  });

                  // select top N slices in content

                  var upperBound = parseInt('3');
                  if (upperBound >= 0) {
                    slicesOfContent = slicesOfContent.slice(0, upperBound);
                  }

                  // highlight title and content

                  function highlightKeyword(text, slice) {
                    var result = '';
                    var prevEnd = slice.start;
                    slice.hits.forEach(function (hit) {
                      result += text.substring(prevEnd, hit.position);
                      var end = hit.position + hit.length;
                      result += '<b class="search-keyword">' + text.substring(hit.position, end) + '</b>';
                      prevEnd = end;
                    });
                    result += text.substring(prevEnd, slice.end);
                    return result;
                  }

                  var resultItem = '';

                  if (slicesOfTitle.length != 0) {
                    resultItem += "<li><a href='" + articleUrl + "' class='search-result-title'>" + highlightKeyword(title, slicesOfTitle[0]) + "</a>";
                  } else {
                    resultItem += "<li><a href='" + articleUrl + "' class='search-result-title'>" + title + "</a>";
                  }

                  slicesOfContent.forEach(function (slice) {
                    resultItem += "<a href='" + articleUrl + "'>" +
                      "<p class=\"search-result\">" + highlightKeyword(content, slice) +
                      "...</p>" + "</a>";
                  });

                  resultItem += "</li>";
                  resultItems.push({
                    item: resultItem,
                    searchTextCount: searchTextCount,
                    hitCount: hitCount,
                    id: resultItems.length
                  });
                }
              })
            };
            if (keywords.length === 1 && keywords[0] === "") {
              resultContent.innerHTML = '<div id="no-result"><i class="fa fa-search fa-5x" /></div>'
            } else if (resultItems.length === 0) {
              resultContent.innerHTML = '<div id="no-result"><i class="fa fa-frown-o fa-5x" /></div>'
            } else {
              resultItems.sort(function (resultLeft, resultRight) {
                if (resultLeft.searchTextCount !== resultRight.searchTextCount) {
                  return resultRight.searchTextCount - resultLeft.searchTextCount;
                } else if (resultLeft.hitCount !== resultRight.hitCount) {
                  return resultRight.hitCount - resultLeft.hitCount;
                } else {
                  return resultRight.id - resultLeft.id;
                }
              });
              var searchResultList = '<ul class=\"search-result-list\">';
              resultItems.forEach(function (result) {
                searchResultList += result.item;
              })
              searchResultList += "</ul>";
              resultContent.innerHTML = searchResultList;
            }
          }

          if ('auto' === 'auto') {
            input.addEventListener('input', inputEventFunction);
          } else {
            $('.search-icon').click(inputEventFunction);
            input.addEventListener('keypress', function (event) {
              if (event.keyCode === 13) {
                inputEventFunction();
              }
            });
          }

          // remove loading animation
          $(".local-search-pop-overlay").remove();
          $('body').css('overflow', '');

          proceedsearch();
        }
      });
    }

    // handle and trigger popup window;
    $('.popup-trigger').click(function(e) {
      e.stopPropagation();
      if (isfetched === false) {
        searchFunc(path, 'local-search-input', 'local-search-result');
      } else {
        proceedsearch();
      };
    });

    $('.popup-btn-close').click(onPopupClose);
    $('.popup').click(function(e){
      e.stopPropagation();
    });
    $(document).on('keyup', function (event) {
      var shouldDismissSearchPopup = event.which === 27 &&
        $('.search-popup').is(':visible');
      if (shouldDismissSearchPopup) {
        onPopupClose();
      }
    });
  </script>





  

  

  

  
  

  
  

  


  
  
  
  <script src="/lib/needsharebutton/needsharebutton.js"></script>

  <script>
    
    
      flOptions = {};
      
          flOptions.iconStyle = "default";
      
          flOptions.boxForm = "horizontal";
      
          flOptions.position = "middleRight";
      
          flOptions.networks = "Weibo,Wechat,Douban,QQZone,Twitter,Facebook";
      
      new needShareButton('#needsharebutton-float', flOptions);
    
  </script>

  

  

  

  

  

  

</body>
</html>
